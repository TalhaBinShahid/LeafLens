# ğŸŒ¿ **LeafLens**

LeafLens is a small full-stack app that helps farmers identify **plant diseases** from images ğŸŒ± and get **short, actionable guidance** through a chat assistant powered by **Google Generative AI (Gemini)** ğŸ¤–.

> â€œThis README provides an overview of the project, its structure, API details, and setup instructions for local development.â€

---

## ğŸ§  **Tech Stack**

| Layer              | Technology                        |
| ------------------ | --------------------------------- |
| **Backend**        | FastAPI, TensorFlow/Keras, Python |
| **Frontend**       | React, TypeScript, Vite           |
| **AI Integration** | Google Generative AI (Gemini)     |

---

## âš™ï¸ **Prerequisites**

Before running the project, ensure you have:

* ğŸ **Python** 3.10 or later
* ğŸ’» **Node.js** 18+ and **npm**
* ğŸ”‘ A valid **Google Gemini API Key** (`GEMINI_API_KEY`)

---

## ğŸŒŸ **Key Features**

âœ¨ Upload an image and receive a predicted disease label
ğŸ’¬ Start a chat session for disease-specific guidance (powered by Gemini)
ğŸ§© Minimal frontend (Vite + React/TypeScript) showcasing image upload, prediction, and chat

---

## ğŸ“– **Quick Glossary / API Contract**

| Feature              | Description                                                                                                         |
| -------------------- | ------------------------------------------------------------------------------------------------------------------- |
| **Predict endpoint** | Accepts an image file and returns `{ predicted_disease: string }`.                                                  |
| **Chat session**     | Start with `{ disease }` â†’ returns `session_id`; send messages `{ session_id, user_message }` â†’ get `{ response }`. |
| **Model**            | `backend/inception_plantvillage.h5` â€” Keras model for plant disease classification.                                 |

---

## ğŸ—‚ï¸ **Repository Structure**

```
LeafLens/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                # FastAPI app (endpoints, model, chat session)
â”‚   â”œâ”€â”€ inception_plantvillage.h5   # Pretrained Keras model
â”‚   â”œâ”€â”€ models.py             # Pydantic request models
â”‚   â””â”€â”€ requirements.txt      # Backend dependencies
â”‚
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ src/lib/api.ts        # Helper for API requests
â”‚   â”œâ”€â”€ src/pages/Detect.tsx  # Image upload & prediction
â”‚   â”œâ”€â”€ src/pages/Results.tsx # Results & chat UI
â”‚   â””â”€â”€ package.json          # Frontend dependencies
```

---

## ğŸ§© **Backend Overview (`backend/app.py`)**

### ğŸ”¹ Endpoints

#### ğŸ§  POST `/predict`

* Accepts an image, preprocesses it (224Ã—224), runs the Keras model, and returns a label.
  **Example response:**

```json
{ "predicted_disease": "Tomato_Early_blight" }
```

#### ğŸ’¬ POST `/start_chat`

* Starts a short-lived chat session.
  **Example response:**

```json
{ "session_id": "...", "message": "Chat started for disease: ..." }
```

#### ğŸ“¤ POST `/chat`

* Sends a user message and gets a Gemini-generated response.
  **Example response:**

```json
{ "response": "Short guidance or reply from Gemini" }
```

#### âŒ POST `/end_chat`

* Ends and deletes a chat session.
  **Example response:**

```json
{ "message": "Chat session ended." }
```

### âš™ï¸ Configuration Notes

* Model file `inception_plantvillage.h5` **must exist** in `backend/`.
* Environment variable `GEMINI_API_KEY` is **required**.
* CORS is configured for:
  `http://localhost:5173`, `http://localhost:3000`, and optional `FRONTEND_URL`.

---

## ğŸ’» **Frontend Usage â€“ `Frontend/src/lib/api.ts`**

Defines helper functions to call backend endpoints:

| Function                                  | Description                    |
| ----------------------------------------- | ------------------------------ |
| `predictPlantDisease(imageFile)`          | Uploads image â†’ `/predict`     |
| `startChatSession(disease)`               | Starts session â†’ `/start_chat` |
| `sendChatMessage(sessionId, userMessage)` | Sends message â†’ `/chat`        |
| `endChatSession(sessionId)`               | Ends session â†’ `/end_chat`     |

**Default API base URL:**
`http://127.0.0.1:5000` (can be overridden via `import.meta.env.SERVER_URL`)

âš ï¸ **Note:**
If you see an error mentioning port `6000`, verify that both the backend and frontend are running on the correct ports (`5000` and `5173` respectively). Update `.env.local` if needed.

---

## ğŸš€ **Setup & Run (Development)**

### ğŸ§© 1) Backend Setup (Windows PowerShell Example)

```powershell
# 1. Create and activate a virtual environment
python -m venv .venv; .\.venv\Scripts\Activate.ps1

# 2. Install dependencies
pip install -r backend/requirements.txt

# 3. Check the model file
dir backend\inception_plantvillage.h5

# 4. Set the Gemini API Key
setx GEMINI_API_KEY "<YOUR_GEMINI_API_KEY>"

# 5. Run backend on port 5000
cd backend
uvicorn app:app --reload --port 5000
```

### ğŸ§  2) Frontend Setup

```powershell
cd Frontend
npm install
npm run dev
# Default: http://localhost:5173
```

### ğŸŒ 3) Run End-to-End

1. Open your browser at `http://localhost:5173`.
2. Upload an image via the **Detect** page.
3. View prediction and start a chat for disease guidance.

---

## ğŸŒ¿ **Screenshot / Demo**

> *(Add your app screenshot or GIF demo here)*

![App Screenshot Placeholder](docs/demo.png)

---

## ğŸ§¾ **Environment Configuration**

| Component    | Variable                     | Description                                |
| ------------ | ---------------------------- | ------------------------------------------ |
| **Backend**  | `GEMINI_API_KEY`             | Required for Gemini chat                   |
| **Backend**  | `FRONTEND_URL`               | (Optional) allowed CORS origin             |
| **Frontend** | `import.meta.env.SERVER_URL` | Set in `.env.local` if backend URL differs |

---

## ğŸ§° **Troubleshooting**

âš ï¸ **Model load errors**

* Ensure `inception_plantvillage.h5` exists and is TensorFlow-compatible.
* Check package versions in `backend/requirements.txt`.

âš ï¸ **API key errors**

* Set `GEMINI_API_KEY` in your environment or `.env`.

âš ï¸ **CORS / Connection issues**

* Confirm backend CORS setup matches frontend origin.
* Ensure both services use the same base URL and port.

---

## ğŸ” **Security & Production Notes**

* Sessions are **in-memory** â€” not persisted.
* Do **not** commit your API key or secrets to GitHub.
* For production, add rate limiting, error handling, and request logging.

---

## ğŸš§ **Next Steps / Suggested Improvements**

âœ… Store chat history in a database
âœ… Add unit and integration tests
âœ… Add health/readiness endpoints
âœ… Improve error messages and unify ports

---

## ğŸ¤ **Contributing**

Pull requests and issues are welcome!
Please include relevant tests for new features and keep PRs focused.

---

## ğŸ“œ **License**

This repository currently has **no license file**.
Add one (e.g., MIT or Apache 2.0) if you plan to open-source it.

---
